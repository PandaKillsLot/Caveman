/**
* Find Duplicate File in System
* https://leetcode.com/problems/find-duplicate-file-in-system/description/
* pro:在系统里查找重复的文件
* tag: 系统设计
* sol: MD5优化, 多线程优化
* mis:  
* fol:
* oth:https://blog.csdn.net/magicbean2/article/details/78986975
*     http://hellokenlee.tk/2017/06/11/leetcode-609/
      https://eugenejw.github.io/2017/07/leetcode-609
*/

class Solution {
    public List<List<String>> findDuplicate(String[] paths) {
        List<List<String>> ans = new ArrayList<List<String>>();
        if (paths == null || paths.length == 0){
            return ans;
        }
        // content, name
        HashMap<String, ArrayList<String>> map = new HashMap<>();
        for (String path : paths){

            sort(path, map);
        }        
        for (Map.Entry<String, ArrayList<String>> entry : map.entrySet()){
            // System.out.println(entry.getKey());
            // System.out.println(entry.getValue());
            if (entry.getValue().size() > 1){
                ans.add(entry.getValue());
            }
            
        }
        return ans;
    }
    private void sort (String path, HashMap<String, ArrayList<String>> map){
        String[] temp = path.split(" ");
        // route
        StringBuilder sb = new StringBuilder(); 
        for (String cur : temp){
            //System.out.println("paths " + path);
            //System.out.println("cur " + cur);
            if (!cur.endsWith(")")){
                sb.append(cur);
            } else {
                String content = cur.substring(cur.indexOf("("), cur.indexOf(")") + 1);
                String name = cur.substring(0, cur.indexOf("("));
                if (!map.containsKey(content)){
                    map.put(content, new ArrayList<String>());
                } 
                // String prefix = sb.toString();
                if (!sb.toString().endsWith("/")){
                    sb.append('/');
                }
                map.get(content).add(sb.toString() + name);
                
            }
        }
    } 
    
    
    /**
    *1.Imagine you are given a real file system, how will you search files? DFS or BFS?
    *--Depends on how many files and how deep the path is, if deep, BFS, if a lot entries, DFS
    *2.If the file content is very large (GB level), how will you modify your solution?
    *--Use file size + file’s MD5. In worst case, we need to compare the files byte by byte.
    *3.If you can only read the file by 1kb each time, how will you modify your solution?
    *--it is not an issue since majority of our files can be differentiate with size + MD5.
    *4.What is the time complexity of your modified solution? What is the most time-consuming part and memory consuming part of it? How to          optimize?
    *-- Time O(n * MD5_calculation), Space (O(N)) : count MD5, map reduce or mulit thread 
    * How to make sure the duplicated files you find are not false positive?
    *-- MD5 must have a collision, make do a random check
    */
}
